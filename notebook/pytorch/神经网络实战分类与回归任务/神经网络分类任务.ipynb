{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mnist分类任务：\n",
    "\n",
    "- 网络基本构建与训练方法，常用函数解析\n",
    "\n",
    "- torch.nn.functional模块\n",
    "\n",
    "- nn.Module模块\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取Mnist数据集\n",
    "- 会自动进行下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"http://deeplearning.net/data/mnist/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "        content = requests.get(URL + FILENAME).content\n",
    "        (PATH / FILENAME).open(\"wb\").write(content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "784是mnist数据集每个样本的像素点个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m pyplot\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m pyplot\u001b[39m.\u001b[39mimshow(x_train[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mreshape((\u001b[39m28\u001b[39m, \u001b[39m28\u001b[39m)), cmap\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgray\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "\n",
    "pyplot.imshow(x_train[0].reshape((28, 28)), cmap=\"gray\")\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/4.png\" alt=\"FAO\" width=\"790\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/5.png\" alt=\"FAO\" width=\"790\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意数据需转换成tensor才能参与后续建模训练\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]) tensor([5, 0, 4,  ..., 8, 4, 8])\n",
      "torch.Size([50000, 784])\n",
      "tensor(0) tensor(9)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x_train, y_train, x_valid, y_valid = map(\n",
    "    torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
    ")\n",
    "n, c = x_train.shape\n",
    "x_train, x_train.shape, y_train.min(), y_train.max()\n",
    "print(x_train, y_train)\n",
    "print(x_train.shape)\n",
    "print(y_train.min(), y_train.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.nn.functional 很多层和函数在这里都会见到\n",
    "\n",
    "torch.nn.functional中有很多功能，后续会常用的。那什么时候使用nn.Module，什么时候使用nn.functional呢？一般情况下，如果模型有可学习的参数，最好用nn.Module，其他情况nn.functional相对更简单一些"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "loss_func = F.cross_entropy\n",
    "\n",
    "def model(xb):\n",
    "    return xb.mm(weights) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.3860, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "bs = 64\n",
    "xb = x_train[0:bs]  # a mini-batch from x\n",
    "yb = y_train[0:bs]\n",
    "weights = torch.randn([784, 10], dtype = torch.float,  requires_grad = True) \n",
    "bs = 64\n",
    "bias = torch.zeros(10, requires_grad=True)\n",
    "\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建一个model来更简化代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 必须继承nn.Module且在其构造函数中需调用nn.Module的构造函数\n",
    "- 无需写反向传播函数，nn.Module能够利用autograd自动实现反向传播\n",
    "- Module中的可学习参数可以通过named_parameters()或者parameters()返回迭代器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Mnist_NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(784, 128)\n",
    "        self.hidden2 = nn.Linear(128, 256)\n",
    "        self.out  = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mnist_NN(\n",
      "  (hidden1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (hidden2): Linear(in_features=128, out_features=256, bias=True)\n",
      "  (out): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Mnist_NN()\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以打印我们定义好名字里的权重和偏置项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden1.weight Parameter containing:\n",
      "tensor([[-0.0190,  0.0228, -0.0052,  ..., -0.0067, -0.0055,  0.0230],\n",
      "        [-0.0126,  0.0175,  0.0004,  ...,  0.0117,  0.0303,  0.0109],\n",
      "        [-0.0051,  0.0195, -0.0265,  ..., -0.0246, -0.0312, -0.0109],\n",
      "        ...,\n",
      "        [-0.0130, -0.0102, -0.0078,  ...,  0.0030, -0.0070,  0.0161],\n",
      "        [ 0.0200,  0.0230, -0.0343,  ...,  0.0211, -0.0285, -0.0206],\n",
      "        [ 0.0084, -0.0259,  0.0319,  ...,  0.0224,  0.0143, -0.0041]],\n",
      "       requires_grad=True) torch.Size([128, 784])\n",
      "hidden1.bias Parameter containing:\n",
      "tensor([ 0.0347,  0.0294, -0.0321, -0.0212, -0.0046, -0.0290, -0.0307,  0.0214,\n",
      "        -0.0210,  0.0118,  0.0045,  0.0072,  0.0038, -0.0352, -0.0357,  0.0289,\n",
      "        -0.0264,  0.0161,  0.0357,  0.0077,  0.0311, -0.0242, -0.0132, -0.0026,\n",
      "         0.0224,  0.0055, -0.0234, -0.0099, -0.0278, -0.0269, -0.0340, -0.0074,\n",
      "         0.0174, -0.0160,  0.0008, -0.0178,  0.0242, -0.0090, -0.0209,  0.0178,\n",
      "         0.0023,  0.0225, -0.0086,  0.0132, -0.0050, -0.0313,  0.0339,  0.0031,\n",
      "         0.0341,  0.0097, -0.0294, -0.0245, -0.0304,  0.0295, -0.0314,  0.0002,\n",
      "         0.0230, -0.0348, -0.0220, -0.0059, -0.0140,  0.0052,  0.0086,  0.0249,\n",
      "         0.0287, -0.0202, -0.0341,  0.0114, -0.0223,  0.0176,  0.0097,  0.0053,\n",
      "         0.0050,  0.0179,  0.0315, -0.0202, -0.0120,  0.0158, -0.0004, -0.0071,\n",
      "        -0.0124,  0.0168,  0.0122,  0.0087,  0.0200,  0.0001,  0.0109,  0.0273,\n",
      "        -0.0168, -0.0175,  0.0072,  0.0196,  0.0029, -0.0331,  0.0039, -0.0024,\n",
      "        -0.0173,  0.0155, -0.0158,  0.0130,  0.0153,  0.0259, -0.0112,  0.0010,\n",
      "         0.0226, -0.0199,  0.0016,  0.0334,  0.0223, -0.0176,  0.0086, -0.0248,\n",
      "        -0.0253, -0.0169, -0.0002,  0.0139, -0.0036,  0.0192, -0.0072, -0.0354,\n",
      "         0.0258,  0.0230, -0.0219, -0.0184, -0.0092, -0.0172, -0.0168, -0.0228],\n",
      "       requires_grad=True) torch.Size([128])\n",
      "hidden2.weight Parameter containing:\n",
      "tensor([[ 0.0078,  0.0718, -0.0829,  ..., -0.0079,  0.0033,  0.0120],\n",
      "        [-0.0053, -0.0401,  0.0323,  ..., -0.0020,  0.0689, -0.0068],\n",
      "        [-0.0615, -0.0554,  0.0330,  ..., -0.0751, -0.0282, -0.0728],\n",
      "        ...,\n",
      "        [-0.0813, -0.0051, -0.0016,  ..., -0.0417,  0.0782,  0.0619],\n",
      "        [ 0.0762,  0.0704,  0.0557,  ..., -0.0396, -0.0569,  0.0345],\n",
      "        [ 0.0598, -0.0020,  0.0164,  ...,  0.0484,  0.0596, -0.0076]],\n",
      "       requires_grad=True) torch.Size([256, 128])\n",
      "hidden2.bias Parameter containing:\n",
      "tensor([ 0.0286,  0.0034, -0.0572,  0.0231,  0.0646,  0.0533,  0.0534, -0.0128,\n",
      "        -0.0740,  0.0302,  0.0109,  0.0203,  0.0754, -0.0458,  0.0747, -0.0731,\n",
      "        -0.0503,  0.0382,  0.0259,  0.0655, -0.0267,  0.0098, -0.0088, -0.0055,\n",
      "         0.0235,  0.0640, -0.0678, -0.0052, -0.0226,  0.0553, -0.0611, -0.0456,\n",
      "        -0.0210,  0.0020,  0.0820,  0.0295, -0.0003,  0.0034, -0.0826, -0.0366,\n",
      "         0.0791, -0.0682,  0.0656,  0.0736, -0.0016, -0.0699, -0.0771, -0.0192,\n",
      "        -0.0264, -0.0157,  0.0881, -0.0872, -0.0676, -0.0139,  0.0156,  0.0199,\n",
      "         0.0422, -0.0194, -0.0630, -0.0519, -0.0361,  0.0606,  0.0365, -0.0294,\n",
      "         0.0292, -0.0762,  0.0302, -0.0882,  0.0753,  0.0446, -0.0538, -0.0102,\n",
      "         0.0645, -0.0207, -0.0445, -0.0452,  0.0291, -0.0675, -0.0707,  0.0156,\n",
      "        -0.0103, -0.0500,  0.0598, -0.0720,  0.0008, -0.0286,  0.0253,  0.0791,\n",
      "        -0.0419,  0.0142,  0.0060,  0.0718,  0.0358,  0.0647,  0.0052, -0.0277,\n",
      "         0.0572, -0.0533, -0.0402, -0.0656,  0.0264, -0.0775, -0.0088,  0.0155,\n",
      "         0.0725,  0.0621, -0.0261,  0.0795, -0.0587,  0.0026,  0.0518, -0.0873,\n",
      "        -0.0737,  0.0177, -0.0236,  0.0518, -0.0037, -0.0617,  0.0806, -0.0427,\n",
      "         0.0092, -0.0241, -0.0126, -0.0034, -0.0646, -0.0246, -0.0590, -0.0217,\n",
      "        -0.0796, -0.0467, -0.0554,  0.0690,  0.0597,  0.0687, -0.0207,  0.0687,\n",
      "        -0.0833,  0.0080,  0.0092, -0.0229,  0.0678, -0.0085, -0.0773, -0.0392,\n",
      "        -0.0512,  0.0420, -0.0705, -0.0837, -0.0597,  0.0634,  0.0003,  0.0557,\n",
      "         0.0232,  0.0751, -0.0423,  0.0660,  0.0616,  0.0167, -0.0615,  0.0057,\n",
      "        -0.0637, -0.0752, -0.0764, -0.0598,  0.0540, -0.0716,  0.0441,  0.0686,\n",
      "         0.0111, -0.0091, -0.0023,  0.0533, -0.0796,  0.0046,  0.0677,  0.0663,\n",
      "        -0.0602, -0.0327, -0.0432,  0.0529,  0.0492,  0.0854,  0.0052, -0.0097,\n",
      "        -0.0015, -0.0210,  0.0240,  0.0249,  0.0587,  0.0536, -0.0086,  0.0706,\n",
      "         0.0162, -0.0496,  0.0290,  0.0298,  0.0766,  0.0809, -0.0749,  0.0075,\n",
      "        -0.0137,  0.0537, -0.0236, -0.0004,  0.0314, -0.0128, -0.0805,  0.0224,\n",
      "        -0.0582, -0.0676,  0.0616,  0.0741, -0.0626, -0.0300,  0.0423,  0.0144,\n",
      "        -0.0097, -0.0803,  0.0800, -0.0567, -0.0290,  0.0277, -0.0527, -0.0169,\n",
      "         0.0686, -0.0665, -0.0283, -0.0856, -0.0345,  0.0831, -0.0331, -0.0537,\n",
      "         0.0564, -0.0777,  0.0828,  0.0488, -0.0621, -0.0375,  0.0055, -0.0691,\n",
      "        -0.0359,  0.0691, -0.0486,  0.0588,  0.0345,  0.0881,  0.0213, -0.0006,\n",
      "        -0.0741,  0.0818, -0.0530, -0.0139, -0.0471, -0.0390, -0.0412,  0.0826],\n",
      "       requires_grad=True) torch.Size([256])\n",
      "out.weight Parameter containing:\n",
      "tensor([[-0.0254,  0.0498, -0.0205,  ...,  0.0456,  0.0174,  0.0330],\n",
      "        [ 0.0300,  0.0471, -0.0013,  ..., -0.0544,  0.0243,  0.0134],\n",
      "        [-0.0121,  0.0611, -0.0298,  ..., -0.0113, -0.0178,  0.0207],\n",
      "        ...,\n",
      "        [-0.0507,  0.0132,  0.0515,  ..., -0.0360,  0.0284,  0.0371],\n",
      "        [ 0.0122, -0.0560,  0.0407,  ..., -0.0302, -0.0062,  0.0580],\n",
      "        [ 0.0622,  0.0296,  0.0361,  ..., -0.0052,  0.0604, -0.0054]],\n",
      "       requires_grad=True) torch.Size([10, 256])\n",
      "out.bias Parameter containing:\n",
      "tensor([-0.0253, -0.0057,  0.0496, -0.0360, -0.0541,  0.0076,  0.0537,  0.0085,\n",
      "         0.0456, -0.0461], requires_grad=True) torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, parameter in net.named_parameters():\n",
    "    print(name, parameter,parameter.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用TensorDataset和DataLoader来简化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "\n",
    "valid_ds = TensorDataset(x_valid, y_valid)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "        DataLoader(valid_ds, batch_size=bs * 2),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 一般在训练模型时加上model.train()，这样会正常使用Batch Normalization和 Dropout\n",
    "- 测试的时候一般选择model.eval()，这样就不会使用Batch Normalization和 Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def fit(steps, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for step in range(steps):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "        print('当前step:'+str(step), '验证集损失：'+str(val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "def get_model():\n",
    "    model = Mnist_NN()\n",
    "    return model, optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三行搞定！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前step:0 验证集损失：2.2741712436676025\n",
      "当前step:1 验证集损失：2.238810009384155\n",
      "当前step:2 验证集损失：2.182846549987793\n",
      "当前step:3 验证集损失：2.0916344299316405\n",
      "当前step:4 验证集损失：1.9448151817321777\n",
      "当前step:5 验证集损失：1.7322513929367065\n",
      "当前step:6 验证集损失：1.4767965171813966\n",
      "当前step:7 验证集损失：1.2307495523452758\n",
      "当前step:8 验证集损失：1.0307839628219604\n",
      "当前step:9 验证集损失：0.8800791104316712\n",
      "当前step:10 验证集损失：0.7683674968719483\n",
      "当前step:11 验证集损失：0.6856172645568848\n",
      "当前step:12 验证集损失：0.6226232534408569\n",
      "当前step:13 验证集损失：0.5744712522506714\n",
      "当前step:14 验证集损失：0.536667770767212\n",
      "当前step:15 验证集损失：0.5062088196277619\n",
      "当前step:16 验证集损失：0.48142317361831666\n",
      "当前step:17 验证集损失：0.4611051800251007\n",
      "当前step:18 验证集损失：0.44392883687019347\n",
      "当前step:19 验证集损失：0.4294238112449646\n",
      "当前step:20 验证集损失：0.41689098663330076\n",
      "当前step:21 验证集损失：0.4065068813085556\n",
      "当前step:22 验证集损失：0.3965473276376724\n",
      "当前step:23 验证集损失：0.38808579473495486\n",
      "当前step:24 验证集损失：0.3806427438974381\n"
     ]
    }
   ],
   "source": [
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "model, opt = get_model()\n",
    "fit(25, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
